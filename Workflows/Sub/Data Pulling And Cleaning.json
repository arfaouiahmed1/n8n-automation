{
  "name": "Data Pulling And Cleaning",
  "nodes": [
    {
      "parameters": {
        "jsCode": "const puppeteer = require('puppeteer');\nconst { newInjectedPage } = require(\"fingerprint-injector\");\n\n// Extract iframe metadata + inner HTML (if same-origin)\nasync function extractIframeMetadata(page) {\n    try {\n        const iframeHandles = await page.$$('iframe'); // Puppeteer element handles\n        const iframes = [];\n\n        for (let index = 0; index < iframeHandles.length; index++) {\n            const iframeHandle = iframeHandles[index];\n\n            // Extract outer attributes (in browser context)\n            const metadata = await page.evaluate((iframe, index) => {\n                const rect = iframe.getBoundingClientRect();\n                return {\n                    index,\n                    src: iframe.src || iframe.getAttribute('src') || '',\n                    title: iframe.title || iframe.getAttribute('title') || '',\n                    width: iframe.width || iframe.getAttribute('width') || rect.width,\n                    height: iframe.height || iframe.getAttribute('height') || rect.height,\n                    frameborder: iframe.frameBorder || iframe.getAttribute('frameborder') || '',\n                    allow: iframe.allow || iframe.getAttribute('allow') || '',\n                    referrerpolicy: iframe.referrerPolicy || iframe.getAttribute('referrerpolicy') || '',\n                    allowfullscreen: iframe.allowFullscreen || iframe.hasAttribute('allowfullscreen'),\n                    sandbox: iframe.sandbox ? iframe.sandbox.toString() : '',\n                    loading: iframe.loading || iframe.getAttribute('loading') || '',\n                    name: iframe.name || iframe.getAttribute('name') || '',\n                    id: iframe.id || '',\n                    className: iframe.className || '',\n                    isVisible: rect.width > 0 && rect.height > 0,\n                    position: {\n                        top: rect.top,\n                        left: rect.left,\n                        bottom: rect.bottom,\n                        right: rect.right\n                    },\n                    iframe: iframe.outerHTML || ''\n                };\n            }, iframeHandle, index);\n\n            // Try to get the iframe document’s HTML (if same-origin)\n            try {\n                const frame = await iframeHandle.contentFrame();\n                if (frame) {\n                    metadata.iframe_html = await frame.evaluate(() => document.documentElement.outerHTML);\n                } else {\n                    metadata.iframe_html = null; // cross-origin or \n                }\n            } catch {\n                metadata.iframe_html = null;\n            }\n\n            iframes.push(metadata);\n        }\n\n        return iframes;\n    } catch (error) {\n        console.error('Error extracting iframe metadata:', error);\n        return [];\n    }\n}\n\n// Check if an iframe is same-origin\nasync function isSameOrigin(page, iframeSrc) {\n    try {\n        const pageUrl = new URL(page.url());\n        const iframeUrl = new URL(iframeSrc);\n        return pageUrl.origin === iframeUrl.origin;\n    } catch (error) {\n        return false;\n    }\n}\n\n// Extract content from same-origin iframe\nasync function extractSameOriginFrameContent(frame, depth = 0) {\n    try {\n        const url = frame.url();\n        const html = await frame.content();\n\n        // Extract text content (cleaned)\n        const text = await frame.evaluate(() => {\n            return document.documentElement.innerText\n                .replace(/[ \\t]+/g, ' ')\n                .replace(/\\n\\s*/g, '\\n')\n                .trim();\n        });\n\n        // Extract metadata\n        const metadata = await frame.evaluate(() => {\n            const meta = {};\n\n            const titleEl = document.querySelector('title');\n            meta.title = titleEl ? titleEl.textContent : '';\n\n            const metaTags = document.querySelectorAll('meta');\n            meta.metaTags = Array.from(metaTags).map(tag => ({\n                name: tag.name || tag.getAttribute('property') || tag.getAttribute('http-equiv'),\n                content: tag.content\n            })).filter(tag => tag.name);\n\n            const scripts = document.querySelectorAll('script[type=\"application/ld+json\"]');\n            meta.structuredData = Array.from(scripts).map(script => {\n                try {\n                    return JSON.parse(script.textContent);\n                } catch {\n                    return null;\n                }\n            }).filter(Boolean);\n\n            return meta;\n        });\n\n        // Optional: Analyze the page as if it were a cross-origin iframe\n        const serviceInfo = analyzeIframeService(url); // you can reuse this function for all URLs\n\n        return {\n            type: 'same-origin',\n            url,\n            depth,\n            html,\n            text,\n            accessible: true,\n            metadata: {\n                ...metadata,\n                platform: serviceInfo.platform,\n                contentType: serviceInfo.contentType,\n                videoId: serviceInfo.videoId,\n                embedUrl: url\n            },\n            screenshot: null, // or set if you choose to capture same-origin screenshots\n            iframeAttributes: null, // to keep consistent structure, though not needed for same-origin\n            children: []\n        };\n    } catch (error) {\n        return {\n            type: 'same-origin-error',\n            url: frame.url() || 'unknown',\n            depth,\n            html: `Content inaccessible: ${error.message}`,\n            text: `Content inaccessible: ${error.message}`,\n            accessible: false,\n            metadata: {},\n            error: error.message,\n            children: []\n        };\n    }\n}\n\n\n// Handle cross-origin iframe (extract what we can without accessing content)\nasync function extractCrossOriginFrameContent(page, iframeData, depth = 0) {\n    try {\n        // For cross-origin iframes, we can't access the content but we can:\n        // 1. Extract all available attributes from the iframe element\n        // 2. Try to take a screenshot of just the iframe area\n        // 3. Analyze the URL to determine the service/platform\n        let screenshot = null;\n        try {\n            const rect = iframeData.position;\n            screenshot = await page.screenshot({\n                clip: {\n                    x: rect.left,\n                    y: rect.top,\n                    width: rect.right - rect.left,\n                    height: rect.bottom - rect.top\n                }\n            });\n        } catch {}\n\n        let serviceInfo = analyzeIframeService(iframeData.src);\n        return {\n            type: 'cross-origin',\n            url: iframeData.src,\n            depth,\n            html: 'Cross-origin content not accessible',\n            text: 'Cross-origin content not accessible',\n            accessible: false,\n            iframeAttributes: iframeData,\n            serviceInfo,\n            screenshot: screenshot,\n            metadata: {\n                platform: serviceInfo.platform,\n                contentType: serviceInfo.contentType,\n                videoId: serviceInfo.videoId,\n                embedUrl: iframeData.src\n            },\n            children: []\n        };\n    } catch (error) {\n        return {\n            type: 'cross-origin-error',\n            url: iframeData.src || 'unknown',\n            depth,\n            html: `Error processing cross-origin iframe: ${error.message}`,\n            text: `Error processing cross-origin iframe: ${error.message}`,\n            accessible: false,\n            error: error.message,\n            children: []\n        };\n    }\n}\n\n// Analyze iframe service based on URL patterns\nfunction analyzeIframeService(src) {\n    if (!src) return { platform: 'unknown', contentType: 'unknown' };\n\n    const url = src.toLowerCase();\n\n    // YouTube\n    if (url.includes('youtube.com/embed') || url.includes('youtu.be')) {\n        const videoIdMatch = src.match(/\\/embed\\/([^?&]+)/);\n        return {\n            platform: 'youtube',\n            contentType: 'video',\n            videoId: videoIdMatch ? videoIdMatch[1] : null\n        };\n    }\n\n    // Vimeo\n    if (url.includes('vimeo.com')) {\n        const videoIdMatch = src.match(/vimeo\\.com\\/(?:video\\/)?(\\d+)/);\n        return {\n            platform: 'vimeo',\n            contentType: 'video',\n            videoId: videoIdMatch ? videoIdMatch[1] : null\n        };\n    }\n\n    // Facebook\n    if (url.includes('facebook.com')) {\n        return {\n            platform: 'facebook',\n            contentType: 'social'\n        };\n    }\n\n    // Twitter/X\n    if (url.includes('twitter.com') || url.includes('x.com')) {\n        return {\n            platform: 'twitter',\n            contentType: 'social'\n        };\n    }\n\n    // Google Maps\n    if (url.includes('google.com/maps')) {\n        return {\n            platform: 'google-maps',\n            contentType: 'map'\n        };\n    }\n\n    // Generic analysis\n    if (url.includes('stream') || url.includes('live') || url.includes('video')) {\n        return {\n            platform: 'unknown',\n            contentType: 'video'\n        };\n    }\n\n    return {\n        platform: 'unknown',\n        contentType: 'unknown'\n    };\n}\n\n// Updated crawlFrames function to handle both same-origin and cross-origin\nasync function crawlFrames(page, frame, result, depth = 0, iframeMetadata = []) {\n    // First, handle the current frame if it's accessible\n    if (frame) {\n        try {\n            const frameData = await extractSameOriginFrameContent(frame, depth);\n            result.children.push(frameData);\n            \n            // Recursively crawl child frames (same-origin)\n            const childFrames = frame.childFrames();\n            for (const childFrame of childFrames) {\n                await crawlFrames(page, childFrame, frameData, depth + 1, iframeMetadata);\n            }\n        } catch (error) {\n            console.error(`Error crawling frame at depth ${depth}: ${error.message}`);\n        }\n    }\n\n    // Handle cross-origin iframes from metadata (only at top level)\n    if (depth === 0 && iframeMetadata.length > 0) {\n        for (const iframeData of iframeMetadata) {\n            // Check if this iframe is cross-origin\n            const sameOrigin = await isSameOrigin(page, iframeData.src);\n            \n            if (!sameOrigin && iframeData.src) {\n                const crossOriginData = await extractCrossOriginFrameContent(page, iframeData, depth + 1);\n                result.children.push(crossOriginData);\n            }\n        }\n    }\n}\n\nasync function checkLayoutElements(page) {\n    try {\n        const result = await page.evaluate(() => {\n            const navClassRegex = /\\b(nav(-?bar)?|navigation)\\b/i;\n    \n            const hasHeader = !!document.querySelector('header');\n            const hasFooter = !!document.querySelector('footer');\n    \n            let hasNav = !!document.querySelector('nav');\n            if (!hasNav) {\n                const elements = document.querySelectorAll('[class]');\n                for (const el of elements) {\n                    if (navClassRegex.test(el.className)) {\n                        hasNav = true;\n                        break;\n                    }\n                }\n            }\n    \n            return { hasHeader, hasFooter, hasNav };\n        });\n    \n        if (!result) {\n            throw new Error(\"No result returned from page.evaluate()\");\n        }\n    \n        return result;\n    } catch (err) {\n        console.error(\"checkLayoutElements failed:\", err);\n        return { hasHeader: false, hasFooter: false, hasNav: false };\n    }\n}\n\nfunction pickRandom(list) {\n    return list[Math.floor(Math.random() * list.length)];\n}\n\n// Main execution\nconst url = $input.first().json.URL;\nif (!url) {\n    throw new Error(\"No URL provided in input\");\n}\n\nconst userAgents = [\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.127 Safari/537.36\",\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.6422.113 Safari/537.36\",\n    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 14_0) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15\",\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.1\",\n    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Linux; Android 14; Pixel 8 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Mobile Safari/537.36\",\n    \"Mozilla/5.0 (Linux; Android 13; SM-G998B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.127 Mobile Safari/537.36\",\n    \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Mobile/15E148 Safari/604.1\",\n];\n\nconst randomUA = pickRandom(userAgents);\n\nconst browser = await puppeteer.launch({\n    headless: \"new\",\n    executablePath: '/usr/bin/chromium-browser',\n    args: [\n        '--start-maximized',\n        '--no-sandbox',\n        '--disable-setuid-sandbox',\n        '--window-size=1280,1024',\n        '--autoplay-policy=no-user-gesture-required',\n        '--disable-gpu',\n        '--disable-software-rasterizer',\n        '--disable-dev-shm-usage',\n        '--no-zygote',\n        '--no-first-run',\n        '--disable-extensions',\n        '--disable-background-networking',\n        '--disable-default-apps',\n        '--mute-audio',\n        '--headless=new',\n        // Added to help with stability\n        '--disable-features=IsolateOrigins,site-per-process'\n    ]\n});\n\ntry {\n    // Reduced initial sleep slightly to save execution time, but kept logic\n    await new Promise(res => setTimeout(res, 2000));\n    \n    const page = await newInjectedPage(browser, {\n        fingerprintOptions: {\n            devices: ['mobile'],\n            operatingSystems: ['ios'],\n        },\n    });\n\n    await page.setViewport({width: 1280, height: 1024});\n    const foundUrls = new Set();\n    page.on('request', req => {\n        const reqUrl = req.url();\n        if (reqUrl.includes('.m3u8') || reqUrl.includes('.ts') || reqUrl.includes('stream') || reqUrl.includes('live')) {\n            foundUrls.add(reqUrl);\n        }\n    });\n\n    await page.setExtraHTTPHeaders({\n        'User-Agent': randomUA\n    });    \n\n    await page.setJavaScriptEnabled(true);\n    await page.setDefaultNavigationTimeout(60000);\n\n    // --- FIX START: Robust Navigation ---\n    try {\n        // Changed from networkidle0 to domcontentloaded to prevent timeouts on streaming sites\n        await page.goto(url, {\n            waitUntil: 'domcontentloaded', \n            timeout: 60000\n        });\n    } catch (navError) {\n        console.log(`Initial navigation timed out or failed: ${navError.message}. Proceeding with loaded content.`);\n    }\n    // --- FIX END ---\n\n    // Wait for dynamic iframes to load (Kept your logic)\n    await new Promise(resolve => setTimeout(resolve, 10000));\n    \n    // --- FIX START: Robust Reload ---\n    try {\n        // Changed from networkidle0 to domcontentloaded\n        await page.reload({waitUntil: 'domcontentloaded'});\n    } catch (reloadError) {\n        console.log(`Reload timed out: ${reloadError.message}. Proceeding.`);\n    }\n    // --- FIX END ---\n\n    await new Promise(resolve => setTimeout(resolve, 10000));\n    \n    // Extract iframe metadata\n    const iframeMetadata = await extractIframeMetadata(page);\n    \n    // Evaluate the presence of header, footer, nav\n    const { hasHeader, hasFooter, hasNav } = await checkLayoutElements(page);\n\n    const content = await page.evaluate(() => {\n        const el = document.querySelector(\"html\");\n        return el ? el.outerHTML : \"NOT FOUND\";\n    });\n    page.content()\n\n    const result = {\n        header_in_html: hasHeader,\n        footer_in_html: hasFooter,\n        nav_in_html: hasNav,\n        mainUrl: page.url(),\n        page_content: content,\n        network: Array.from(foundUrls),\n        iframes: iframeMetadata,\n        children: []\n    };\n\n    // Crawl frames for the main page\n    await crawlFrames(page, page.mainFrame(), result, 0, iframeMetadata);\n\n    return [{ json: result }];\n\n} catch (error) {   \n    console.error('Error during processing:', error);\n    throw error;\n} finally {\n    await browser.close();\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1840,
        384
      ],
      "id": "6ac46ff7-ba57-43a1-9461-0801a5b39fda",
      "name": "Puppeteer"
    },
    {
      "parameters": {
        "jsCode": "const cheerio = require('cheerio');\nconst { minify } = require('html-minifier-terser');\nconst puppeteer = require('puppeteer');\nconst https = require('https');\n\n// ========================================\n// REGEX & CONSTANTS\n// ========================================\nconst URL_EXTRACTOR = /https?:\\/\\/[^\\s\"'<>]+/g;\nconst URL_VALIDATOR = new RegExp(\n  '^(https?:\\\\/\\\\/)?' +\n    \"(?:www\\\\.)?\" +\n    '[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}' +\n    '\\\\.[a-zA-Z0-9()]{1,6}\\\\b' +\n    '(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$'\n);\n\n// ========================================\n// HELPER FUNCTIONS\n// ========================================\n\nfunction isValidUrl(url) {\n  return Boolean(URL_VALIDATOR.test(url));\n}\n\nasync function getCleanedHtml(soupHtml) {\n  try {\n    const minified = await minify(soupHtml, {\n      collapseWhitespace: true,\n      removeComments: true,\n      removeAttributeQuotes: false,\n      keepClosingSlash: true,\n      minifyCSS: true,\n      minifyJS: true,\n      removeRedundantAttributes: true,\n      removeEmptyAttributes: false,\n      conservativeCollapse: true,\n      collapseBooleanAttributes: true,\n      sortAttributes: true,\n      sortClassName: true,\n    });\n    return minified;\n  } catch (e) {\n    return soupHtml;\n  }\n}\n\nfunction extractScriptUrlsFromCheerio($) {\n  const urls = [];\n  $('script').each((i, el) => {\n    const txt = $(el).html() || $(el).text() || '';\n    let m;\n    while ((m = URL_EXTRACTOR.exec(txt))) {\n      urls.push(m[0]);\n    }\n  });\n  return urls;\n}\n\nfunction removeUnwantedTags($, { removeScripts = true, removeStyles = true, excludedTags = [] } = {}) {\n  const tagsToRemove = new Set(excludedTags || []);\n  if (removeScripts) tagsToRemove.add('script');\n  if (removeStyles) tagsToRemove.add('style');\n  for (const t of tagsToRemove) {\n    $(t).remove();\n  }\n}\n\nfunction removeTagsWithAttributes($, excludedAttributes = []) {\n  if (!excludedAttributes || excludedAttributes.length === 0) return;\n  const selector = '*';\n  $(selector).each((i, el) => {\n    const attribs = el.attribs || {};\n    for (const attr of excludedAttributes) {\n      if (Object.prototype.hasOwnProperty.call(attribs, attr)) {\n        $(el).remove();\n        break;\n      }\n    }\n  });\n}\n\nfunction processImages($, { keepImages = false, removeSvg = true, removeGif = true, excludedImageTypes = [] } = {}) {\n  if (!keepImages) {\n    $('img').remove();\n    return;\n  }\n  const removeExts = new Set((excludedImageTypes || []).map((e) => (e.startsWith('.') ? e.toLowerCase() : '.' + e.toLowerCase())));\n  if (removeSvg) removeExts.add('.svg');\n  if (removeGif) removeExts.add('.gif');\n\n  $('img').each((i, el) => {\n    const src = (el.attribs && (el.attribs.src || el.attribs['data-src'] || '')) || '';\n    const lower = src.toLowerCase();\n    let remove = false;\n    for (const ext of removeExts) {\n      if (lower.endsWith(ext)) {\n        remove = true;\n        break;\n      }\n    }\n    if (remove || !src) {\n      $(el).remove();\n    } else {\n      $(el).replaceWith(`\\n[IMAGE: ${src}]\\n`);\n    }\n  });\n}\n\nfunction processLinks($) {\n  const links = [];\n  $('a').each((i, el) => {\n    const href = (el.attribs && (el.attribs.href || '')).trim();\n    if (!href) return;\n    let normalized = href;\n    if (normalized.startsWith('//')) normalized = 'https:' + normalized;\n    const text = $(el).text().trim();\n    const title = (el.attribs && el.attribs.title) ? el.attribs.title.trim() : undefined;\n    const parent = $(el).parent();\n    const parentText = parent ? parent.text().trim() : undefined;\n    const linkData = { url: normalized };\n    if (text) linkData.text = text;\n    if (title) linkData.title = title;\n    if (parentText) linkData.parent_text = parentText;\n    links.push(linkData);\n  });\n  return links;\n}\n\nfunction removeAllLinks($) {\n  $('a').remove();\n}\n\nfunction extractVisibleTextFromHtml(html) {\n  const $ = cheerio.load(html, { decodeEntities: false });\n  const text = $('body').text() || $.root().text();\n  return text.replace(/\\s+\\n/g, '\\n').replace(/\\n\\s+/g, '\\n').replace(/[ \\t]{2,}/g, ' ').trim();\n}\n\nfunction detectMetaDescription($) {\n  const metaDesc = $('meta[name=\"description\"]').attr('content') || $('meta[property=\"og:description\"]').attr('content') || '';\n  return metaDesc ? metaDesc.trim() : '';\n}\n\nfunction detectSuspiciousPatterns(html) {\n  const patterns = [];\n  if (/document\\.write\\(/i.test(html)) patterns.push('document.write');\n  if (/eval\\(/i.test(html)) patterns.push('eval');\n  if (/base64,/.test(html)) patterns.push('base64');\n  if (/data:\\s*image\\/svg\\+xml/i.test(html)) patterns.push('inline-svg-data');\n  if (/javascript:/i.test(html)) patterns.push('javascript:links');\n  if (/<iframe\\s+[^>]*src=[\"']?data:/i.test(html)) patterns.push('iframe-data-src');\n  const scriptMatches = html.match(/<script\\b[^>]*>([\\s\\S]{200,})<\\/script>/i);\n  if (scriptMatches) patterns.push('long-inline-script');\n  return patterns;\n}\n\nfunction detectSuspiciousPlayers(html) {\n  const players = new Set();\n  const pCandidates = ['jwplayer', 'videojs', 'plyr', 'hls', 'dash', 'youtube', 'vimeo', 'brightcove', 'wistia'];\n  const lower = html.toLowerCase();\n  for (const p of pCandidates) {\n    if (lower.includes(p)) players.add(p);\n  }\n  return Array.from(players);\n}\n\nfunction detectKeywords(text, maxKeywords = 10) {\n  if (!text) return [];\n  const stopwords = new Set([\n    'the','and','a','to','of','in','is','it','you','that','he','was','for','on','are','as','with','his','they','i','at','be',\n    'this','have','from','or','one','had','by','word','but','not','what','all','were','we','when','your','can','said','there',\n    'use','each','which','she','do','how','their','if','will','up','other','about','out','many','then','them','these','so',\n    'some','her','would','make','like','him','into','time','has','look','two','more','write','go','see','number','no','way',\n    'could','people','my','than','first','water','been','call','who','oil','its','now','find','long','down','day','did','get',\n    'come','made','may','part'\n  ]);\n  const tokens = text\n    .replace(/[\\W_]+/g, ' ')\n    .toLowerCase()\n    .split(/\\s+/)\n    .filter(Boolean)\n    .filter((t) => t.length > 2 && !stopwords.has(t));\n  if (tokens.length === 0) return [];\n  const freq = {};\n  for (const t of tokens) freq[t] = (freq[t] || 0) + 1;\n  const sorted = Object.entries(freq).sort((a, b) => b[1] - a[1]).slice(0, maxKeywords);\n  return sorted.map((s) => s[0]);\n}\n\n/**\n * FIXED: Properly extracts URL and HTML from input objects regardless of key names\n */\nfunction rankIframes(iframes = []) {\n  if (!Array.isArray(iframes) || iframes.length === 0) return [];\n  \n  const scored = iframes.map((fr) => {\n    // 1. Standardize keys: Look for multiple possibilities\n    const rawUrl = fr.url || fr.embedUrl || fr.src || fr.iframe || null;\n    const rawHtml = fr.html || fr.iframe_html || fr.content || fr.body || '';\n    const type = fr.type || '';\n\n    let score = 0;\n    \n    // Score based on type\n    if (type.toLowerCase().includes('same-origin')) score += 10;\n    \n    // Score based on HTML length\n    const htmlLen = rawHtml.length;\n    score += Math.min(10, Math.floor(htmlLen / 200));\n\n    return { \n        iframe: rawUrl, \n        iframe_html: rawHtml, \n        score, \n        raw: fr \n    };\n  });\n  \n  // Sort descending by score\n  scored.sort((a, b) => b.score - a.score);\n  return scored;\n}\n\nasync function processHtmlContent(htmlContent, opts = {}) {\n  const {\n    keep_images = false,\n    remove_svg = true,\n    remove_gif = true,\n    excluded_image_types = [],\n    keep_links = true,\n    remove_scripts = true,\n    remove_styles = true,\n    excluded_tags = [],\n    excluded_attributes = [],\n    return_html = false,\n  } = opts || {};\n\n  try {\n    const $ = cheerio.load(htmlContent || '', { decodeEntities: false });\n    const scriptUrls = remove_scripts ? extractScriptUrlsFromCheerio($) : [];\n    if (excluded_attributes && excluded_attributes.length > 0) removeTagsWithAttributes($, excluded_attributes);\n    removeUnwantedTags($, { removeScripts: remove_scripts, removeStyles: remove_styles, excludedTags: excluded_tags });\n    processImages($, { keepImages: keep_images, removeSvg: remove_svg, removeGif: remove_gif, excludedImageTypes: excluded_image_types });\n    \n    let pageLinks = [];\n    if (keep_links) {\n      pageLinks = processLinks($);\n    } else {\n      removeAllLinks($);\n    }\n\n    const body = $('body').length ? $('body').html() : $.root().html();\n    const cleaned_html = await getCleanedHtml(body || '');\n    const text_content = extractVisibleTextFromHtml(cleaned_html);\n\n    return {\n      cleaned_html: return_html ? cleaned_html : '',\n      text_content,\n      script_urls: Array.from(new Set(scriptUrls)),\n      page_links: pageLinks,\n    };\n  } catch (e) {\n    return {\n      cleaned_html: '',\n      text_content: '',\n      script_urls: [],\n      page_links: [],\n    };\n  }\n}\n\n// ========================================\n// SCREENSHOT FUNCTION\n// ========================================\nasync function uploadToCloudinary(imageBuffer) {\n  const CLOUDINARY_CLOUD_NAME = process.env.CLOUDINARY_CLOUD_NAME || \"dktc34wxa\";\n  const CLOUDINARY_UPLOAD_PRESET = process.env.CLOUDINARY_UPLOAD_PRESET || \"n8n-Ahmed\";\n\n  if (!CLOUDINARY_CLOUD_NAME || !CLOUDINARY_UPLOAD_PRESET) {\n    // throw new Error(`Cloudinary credentials missing`); \n    console.log(\"Cloudinary credentials missing, skipping upload.\");\n    return null;\n  }\n\n  const base64Image = `data:image/png;base64,${imageBuffer.toString('base64')}`;\n  const formData = {\n    file: base64Image,\n    upload_preset: CLOUDINARY_UPLOAD_PRESET,\n  };\n\n  const boundary = \"----n8nCloudinaryBoundary\" + Math.random().toString(16).slice(2);\n  let body = \"\";\n\n  for (const [key, value] of Object.entries(formData)) {\n    body += `--${boundary}\\r\\n`;\n    body += `Content-Disposition: form-data; name=\"${key}\"\\r\\n\\r\\n`;\n    body += `${value}\\r\\n`;\n  }\n  body += `--${boundary}--\\r\\n`;\n\n  return new Promise((resolve, reject) => {\n    const req = https.request(\n      {\n        hostname: \"api.cloudinary.com\",\n        port: 443,\n        path: `/v1_1/${CLOUDINARY_CLOUD_NAME}/image/upload`,\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": `multipart/form-data; boundary=${boundary}`,\n          \"Content-Length\": Buffer.byteLength(body),\n        },\n      },\n      (res) => {\n        let data = \"\";\n        res.on(\"data\", (chunk) => (data += chunk));\n        res.on(\"end\", () => {\n          if (res.statusCode === 200) {\n            try {\n                resolve(JSON.parse(data).secure_url);\n            } catch(e) { reject(e); }\n          } else {\n            reject(new Error(`Cloudinary upload failed: ${data}`));\n          }\n        });\n      }\n    );\n    req.on(\"error\", reject);\n    req.write(body);\n    req.end();\n  });\n}\n\nasync function captureAndUploadScreenshot(url) {\n  if (!url) return null;\n  \n  // Launch puppeteer\n  const browser = await puppeteer.launch({\n    headless: \"new\",\n    executablePath: '/usr/bin/chromium-browser',\n    args: [\n      \"--no-sandbox\",\n      \"--disable-setuid-sandbox\",\n      \"--disable-dev-shm-usage\",\n      \"--disable-gpu\",\n      \"--no-zygote\",\n      \"--no-first-run\",\n      \"--disable-extensions\",\n      \"--disable-background-networking\",\n      \"--disable-default-apps\",\n      \"--mute-audio\",\n      \"--headless=new\"\n    ],\n  });\n\n  try {\n    const page = await browser.newPage();\n    await page.setViewport({ width: 1280, height: 800 });\n    // Standard User Agent\n    await page.setUserAgent(\n      \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n    );\n\n    // Timeout increased for safety\n    await page.goto(url, { waitUntil: \"domcontentloaded\", timeout: 30000 });\n    await page.waitForTimeout(1500); // slight delay for rendering\n\n    const buffer = await page.screenshot({ fullPage: true });\n    const imageUrl = await uploadToCloudinary(buffer);\n    return imageUrl;\n  } catch (error) {\n    console.error('Screenshot capture failed:', error.message);\n    return null;\n  } finally {\n    await browser.close();\n  }\n}\nfunction detectLayoutFromHtml(html) {\n  if (!html) return { hasHeader: false, hasFooter: false, hasNav: false };\n\n  const $ = cheerio.load(html, { decodeEntities: false });\n\n  return {\n    hasHeader: $('header').length > 0,\n    hasFooter: $('footer').length > 0,\n    hasNav: $('nav').length > 0\n  };\n}\n\n// ========================================\n// MAIN FEATURE EXTRACTION FUNCTION\n// ========================================\nasync function extractFeaturesFromHtml(data = {}) {\n  // Safe extraction of properties\n  const pageContent = data.pageContent || data.page_content || data.html || '';\n  const layout = {\n      hasHeader: data.header_in_html || false,\n      hasFooter: data.footer_in_html || false,\n      hasNav: data.nav_in_html || false\n  }; \n  const network = data.network || data.page_network || [];\n  const iframes = data.iframes || data.children || [];\n  const mainUrl = data.mainUrl || data.url || data.main_url || null;\n\n  // Process main page HTML\n  const page_features = await processHtmlContent(pageContent, { excluded_tags: ['footer'] });\n\n  // Rank and process iframes\n  // FIXED: Now we rely on the standardized output from rankIframes\n  const ranked = rankIframes(iframes);\n  const topIframe = ranked.length ? ranked[0] : null;\n\n  let final_iframe_url = '';\n  let final_iframe_html = '';\n\n  if (topIframe) {\n    // Get URL (already standardized in rankIframes)\n    final_iframe_url = topIframe.iframe || '';\n    \n    // Get HTML (already standardized in rankIframes)\n    const rawIframeHtml = topIframe.iframe_html || '';\n\n    if (rawIframeHtml) {\n      const processed_iframe_html = await processHtmlContent(rawIframeHtml, { return_html: true });\n      final_iframe_html = processed_iframe_html.cleaned_html || '';\n      \n      // Merge links from iframe into main page links\n      if (processed_iframe_html.page_links && processed_iframe_html.page_links.length) {\n        page_features.page_links = (page_features.page_links || []).concat(processed_iframe_html.page_links);\n      }\n    }\n  }\n\n  // Extract meta/keywords\n  const $main = cheerio.load(pageContent || '', { decodeEntities: false });\n  const visible_text = $main.text().replace(/\\s+/g, ' ').trim();\n\n  const meta_description = detectMetaDescription($main);\n  const patterns = detectSuspiciousPatterns(pageContent || '');\n  const players = detectSuspiciousPlayers(pageContent || '');\n  const keywords = detectKeywords(visible_text);\n  \n  // Capture Screenshot (if URL exists)\n  let screenshot_url = null;\n  if (mainUrl) {\n    console.log(`Capturing screenshot for ${mainUrl}...`);\n    screenshot_url = await captureAndUploadScreenshot(mainUrl);\n  }\n\n  return {\n    mainUrl,\n    page_links: page_features.page_links || [],\n    page_text_content: page_features.text_content || '',\n    page_has_header: layout.hasHeader || false,   // ✅ Use layout from data\n    page_has_footer: layout.hasFooter || false,   // ✅ Use layout from data\n    page_has_navbar: layout.hasNav || false,   \n\n    page_network: network,\n    players_found: players,\n    iframe: final_iframe_url,\n    iframe_html: final_iframe_html,\n    suspicious_patterns: patterns,\n    meta_description,\n    keywords,\n    screenshot_url: screenshot_url,\n  };\n}\n\n// ========================================\n// N8N MAIN FUNCTION\n// ========================================\nasync function main() {\n  // Standard n8n input handling\n  const inputItems = items && items.length ? items : (Array.isArray($input?.all()) ? $input.all() : []);\n\n  const results = [];\n  for (let idx = 0; idx < inputItems.length; idx++) {\n    const item = inputItems[idx];\n    const inputJson = item.json || item;\n\n    // Handle nested arrays which sometimes happen in batching\n    if (Array.isArray(inputJson)) {\n        for (const el of inputJson) {\n            const features = await extractFeaturesFromHtml(el);\n            results.push(features);\n        }\n    } else {\n        const features = await extractFeaturesFromHtml(inputJson);\n        results.push(features);\n    }\n  }\n\n  return results.map((r) => ({ json: r }));\n}\n\nreturn main();"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1616,
        384
      ],
      "id": "143c45e7-933f-4256-ac10-befe8ff1c182",
      "name": "Cleaner"
    },
    {
      "parameters": {
        "inputSource": "jsonExample",
        "jsonExample": "  \n{\n  \n  \n\"URL\": \n\"https://www.syria-live.tv/yalla-koora/\",\n  \n  \n\"id\": \n1,\n  \n  \n\"createdAt\": \n\"2025-12-04T18:15:52.323Z\",\n  \n  \n\"updatedAt\": \n\"2025-12-10T12:35:31.906Z\"\n  \n}\n"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -2128,
        384
      ],
      "id": "b70fc381-74d7-4a3c-8a0b-fa358e66fd51",
      "name": "When Executed by Another Workflow"
    }
  ],
  "pinData": {
    "When Executed by Another Workflow": [
      {
        "json": {
          "URL": "https://freeshot.live/",
          "id": null,
          "createdAt": null,
          "updatedAt": null
        },
        "pairedItem": {
          "item": 0
        }
      }
    ]
  },
  "connections": {
    "Puppeteer": {
      "main": [
        [
          {
            "node": "Cleaner",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Puppeteer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "9a199a65-fdc7-4b35-a703-7bcd96b5ad41",
  "meta": {
    "instanceId": "124a121e0eabe92019aa153b650b882fcdfc854cce820e5d5a87469c3bc4a426"
  },
  "id": "OMNWvcX4lRKityBq",
  "tags": []
}